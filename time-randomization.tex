\subsection{Threat Model}\label{threat-model}
The type of attack that time randomization seeks to thwart has the following properties:
\begin{itemize}
	\item The attack targets a concurrency bug.
	\item The attacker can gain knowledge about the relative timing between two
  or more threads relevant to the bug.
	\item The attacker leverages this knowledge to craft the attack.
\end{itemize}
Note that there are many ways to gain knowledge about relative thread timing, including results from fuzzing experiments.
In the case that the fuzzing is done on a binary, it may not even be obvious how many threads are involved.
Nevertheless, positive fuzzing results can be considered knowledge about relative thread timing which can then be used to craft an attack.

As an example, consider the following scenario:
A remote attacker is communicating with some server software, and has somehow become aware of a concurrency bug in that software.
They have devised a way to exploit the bug, which includes a method for inducing a buggy thread interleaving.
For concreteness, let's assume that the bug is exposed when a save operation
is attempted by one thread during the critical section of another save
operation in another thread (e.g., after some checking has been done, but before the results have been used, sometimes referred to as a time of check to time of use attack).
If the server immediately spawns threads to execute save operations in response to client requests, the attacker's work consists of identifying the proper delay between two save threads such that the critical sections intersect.
The critical sections in this context are sometimes referred to as a vulnerability window~\cite{Yang2012}.

If the server software is available to the attacker, they can simply study it on a similar system (which they control) to determine the appropriate delay required to expose the bug.
Armed with this knowledge, they stand a good chance of exploiting the bug on the target system by sending requests with the same delay.
\subsection{Implementation}\label{implementation}
Time randomization, the randomization of synchronization schedules and thread interleavings, as well as the relative timing between and among threads, aims to make this type of attack much harder.
By making the relative timing between threads less predictable, the cost of carrying out the attack above is dramatically increased.

Of the various software diversity transformations which have been studied~\cite{Larsen2014}, the ones which are most applicable to time randomization are those which
\begin{itemize}
	\item add delays to a thread or threads, and those which
	\item reorder something such that thread interleaving is affected.
\end{itemize}
The first category is almost always possible, as adding delays rarely breaks programs.
However, an obvious drawback to this approach is loss of performance, and this drawback must be weighed against the benefits of the transformation.
In the second case, the ``something'' reordered can be at any granularity (instruction level, function level, program level, etc.) so long as thread interleaving is affected.
These types of transformations are less likely to have performance costs, but they are more likely to break the correctness of programs.
This work studies three transformations in the first category.

The three transformations for introducing automated diversity explored in the context of concurrency attacks in this work consist of interposing external library calls~\cite{Conrod2009} made by the software to be protected each with random numbers of inline assembly NOP instructions.
This was accomplished in two steps: first by specifying the library functions to be interposed; and second by interposing those functions with NOP loops.

The way that the library functions are chosen for interposition distinguishes among the three transformations studied.
The first transformation chooses all external library function calls indiscriminately, while the other two use synchronization mechanisms to indicate locations where delays may have the greatest effect on relative thread timing.
In all transformations, \texttt{ltrace}~\cite{cespedesltrace} is run on the unmodified program to be protected while it is being subjected to an exploit attempt.
Using the log from that ltrace run,
\begin{description}
	\item[T1] the first transformation chooses every external library function call for interposition,
	\item[T2] the second transformation chooses every external library function call immediately preceding a synchronization mechanism, and
	\item[T3] the third transformation chooses every external library function call immediately following a synchronization mechanism.
\end{description}
(Hereafter, these transformations are referred to as \textbf{T1}, \textbf{T2}, and \textbf{T3}.)
Functions were only excluded in the rare cases that the function takes a
variable argument list, or interposing the function interferes with the
interposition method itself (e.g., \texttt{sigsetjmp}).
Both cases are unsuitable for the interposition method used in this work.
As all of the experiments were conducted on Linux, ``synchronization
mechanisms'' were generally identified as \texttt{pthread} function calls, except for the case of Libvirt which redefines its own synchronization mechanisms.

Once the functions were chosen for interposition, NOP loops were interposed as described in the tutorial cited above~\cite{Conrod2009}.
First a max delay was specified (per interposition).
Then, for each of the external library functions chosen for interposition, a random integer between zero and the max delay was selected.
Finally, that number was used as the loop limit on a loop of a single assembly NOP interposed before that external library function.
The interpositions of the NOP loops were compiled into a dynamic library file, and that file was specified to be preloaded with the LD\_PRELOAD environment variable.

More specifically, a C file was generated (including any necessary headers) which redefined each of the library functions chosen for interposition.
Each of these redefinitions consisted of exactly the following pieces:
\begin{enumerate}
	\item declaration of a function pointer of the same type as the function being redefined (to be used to call the original library function),
	\item a \texttt{for} loop with a loop limit chosen as described above, and a body consisting of the single statement \texttt{asm("nop;");},
	\item assignment of the original library function (via \texttt{dlsym}) to the function pointer declared in 1., and
	\item a call to the original library function, returning the return value.
\end{enumerate}
This file was then compiled as a dynamic library \texttt{interpose.so} to be preloaded at runtime before each experiment.