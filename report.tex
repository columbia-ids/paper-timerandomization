% TEMPLATE for Usenix papers, specifically to meet requirements of
%  USENIX '05
% originally a template for producing IEEE-format articles using LaTeX.
%   written by Matthew Ward, CS Department, Worcester Polytechnic Institute.
% adapted by David Beazley for his excellent SWIG paper in Proceedings,
%   Tcl 96
% turned into a smartass generic template by De Clarke, with thanks to
%   both the above pioneers
% use at your own risk.  Complaints to /dev/null.
% make it two column with no page numbering, default is 10 point

% Munged by Fred Douglis <douglis@research.att.com> 10/97 to separate
% the .sty file from the LaTeX source template, so that people can
% more easily include the .sty file into an existing document.  Also
% changed to more closely follow the style guidelines as represented
% by the Word sample file. 

% Note that since 2010, USENIX does not require endnotes. If you want
% foot of page notes, don't include the endnotes package in the 
% usepackage command, below.

% This version uses the latex2e styles, not the very ancient 2.09 stuff.
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,epsfig,endnotes,hyperref,listings,textcomp}
\lstset{
	basicstyle=\ttfamily,
	showstringspaces=false,
	escapechar=\%,
	breaklines=true,
	numbers=left,
	%xleftmargin=2em
}
\begin{document}

%don't want date printed
\date{\today}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Time Randomization to Thwart Concurrency Bug Exploitation}

%for single author (just remove % characters)
\author{
{\rm David M. Tagatac}\\
Columbia University
\and
{\rm Tony Ling}\\
Columbia University
\and
{\rm Michalis Polychronakis}\\
Columbia University
\and
{\rm Salvatore J. Stolfo}\\
Columbia University
% copy the following lines to add more authors
% \and
% {\rm Name}\\
%Name Institution
} % end author

\maketitle

% Use the following at camera-ready time to suppress page numbers.
% Comment it out when you first submit the paper for review.
%\thispagestyle{empty}


\subsection*{Abstract}
Your Abstract Text Goes Here.  Just a few facts.
Whet our appetites.

\section{Introduction}
With the pervasiveness of multicore architectures, multithreading is an important - and often necessary - tool when programming for performance.  However, programming with multiple threads is generally more difficult than programming for serial execution.  Each thread has the potential to contain any bug of a serial program, and on top of that, the uncertain interleaving of concurrent threads has the potential for concurrency bugs (e.g. data races).

Lu et al. did a survey of concurrency bugs \cite{Lu2008}, and Yang et al. has demonstrated that attacks on buggy multithreaded programs are a real concern \cite{Yang2011}.  Much of the effort in combating this threat has gone into tools and systems which detect data races in order to aid debugging \cite{Savage1997, Flanagan2004, Laadan2011, Pratikakis2011, Kasikci2013}.  An alternative approach is to guide multithreaded programs into memoized synchronization schedules \cite{Cui2011}.  This approach does not dwell on race detection, but rather on removing the nondeterminism from the portions of multithreaded programs where races are most likely.  However, schedule memoization in its most automated form is still susceptible to attack whenever the attacker can trigger a different schedule by changing the input.

We address the threat of concurrency attacks from yet another angle.  Much like the way that address space layout randomization thwarts attacks that depend on absolute and/or relative code and data addresses in memory, we propose to thwart concurrency attacks that depend on specific thread timing by randomizing the delays between and among threads.  Like the memoization approach described above, we also focus on the synchronization schedule (the interleaving of the various threads in a multithreaded program).  However, instead of removing nondeterminism to increase reproducibility, we attempt to randomize the synchronization schedule to remove the possibility that the relative timing of two (or more) threads can be studied and used to craft an attack.  For this subset of concurrency attacks which depend on thread timing, we hypothesize that random injection of timing delays between concurrent threads will reduce the chance of any specific attack's success.  If such an attack can address different thread timing with correspondingly different input timing, at least randomization increases the cost to the attacker to determine the appropriate input timing; moreover, that knowledge is only useful for one system until the next randomization.

\section{Time Randomization}

\section{Experimental Design}
\subsection{CVE-2005-1125}
To test both the efficacy and the performance of time randomization as a mechanism to thwart concurrency bug exploitation, we applied time randomization to Libsafe 2.0-16.  This version of Libsafe contains a concurrency bug, for which there is publicly available proof of concept exploit.

The bug works as follows:

\subsection{Instrumentation}

\section{Analysis}

\section{Future Work}

\section{Related Work}

\section{Conclusion}


%\section{Preliminary Effectiveness Results}
%\begin{figure}
%\begin{lstlisting}[firstnumber=43]
%static inline long do_mmap2(
%unsigned long addr, unsigned long len,
%unsigned long prot, unsigned long flags,
%unsigned long fd, unsigned long pgoff)
%{
%	int error = -EBADF;
%	struct file * file = NULL;
%
%	flags &= ~(MAP_EXECUTABLE | MAP_DENYWRITE);
%	if (!(flags & MAP_ANONYMOUS)) {
%		file = fget(fd);
%		if (!file)
%			goto out;
%	}
%	%\textbf{udelay(100);}%
%	down_write(&current->mm->mmap_sem);
%	error = do_mmap_pgoff(file, addr, len, prot, flags, pgoff);
%	up_write(&current->mm->mmap_sem);
%
%	if (file)
%		fput(file);
%out:
%	return error;
%}
%\end{lstlisting}
%\caption{An example targeted timing delay in the CentOS Linux kernel 2.4.21 in function do\_mmap2 in arch/i386/kernel/sys\_i386.c, line 57.}
%\label{fig_mmapcode}
%\end{figure}
%\begin{figure}
%\centering
%\includegraphics[width=\columnwidth]{prelimgraph}
%\caption{The effect of placing targeted timing delays in the (buggy) CentOS Linux kernel 2.4.21.  Delays between 0 and 5,000{\textmu}s were inserted strategically to alter concurrent thread timing, and the number of failed exploit script runs prior to a successful exploit strictly increased with the length of the inserted delay.}
%\label{fig_prelimgraph}
%\end{figure}
%To motivate the plausibility of our approach, we first tested the effects of targeted timing delays in buggy multithreaded code for which we have an exploit script.  The CentOS 3.9 kernel (from Linux 2.4.21) contains a critical concurrency bug that causes a system hang when exploited \cite{CVE2006-4814}.  The bug is a deadlock on the mmap semaphore `mmap\_sem' that is triggered by a specific interleaving of concurrent threads, one calling the mmap system call and the other calling the mincore system call.  The Red Hat bug report \cite{RHELbug180663} provides a script which creates two threads - one that repeatedly calls mincore in a loop, and another that repeatedly calls mmap in a loop.  By placing calls to usleep() just before the call to down\_write on mmap\_sem in the i386 architecture-specific implementation of mmap (Figure \ref{fig_mmapcode}), we were able to alter the timing of the thread interleaving.  We observed that the number of exploit script runs required for a successful exploit strictly increased with the duration of the sleep inserted (Figure \ref{fig_prelimgraph}).
%
%\section{Preliminary Performance Cost Results}
%After observing that targeted timing delays reduce the success rate of at least one concurrency bug exploit, it is relevant to ask about the performance cost of these timing delays.  I chose to run three of the core SPLASH-2 benchmarks \cite{Woo1995} as they presented the least trouble compiling on an operating system as old as CentOS 3.9.  In particular, I ran the Contiguous Partitions Ocean Simulation, the Hierarchical Radiosity Application, and the Water Simulation with Spatial Data Structure.  Each application was run three times for each delay insertion length, and then averaged to obtain the results below.
%\subsection{Ocean Simulation}
%\begin{figure}
%\centering
%\includegraphics[width=\columnwidth]{ocean}
%\caption{The performance cost on the SPLASH-2 application OCEAN of placing targeted timing delays in the CentOS Linux kernel 2.4.21.}
%\label{fig_ocean}
%\end{figure}
%The Ocean Simulation in the SPLASH-2 benchmark suite simulates large-scale ocean movements based on eddy and boundary currents.  The Contiguous Partitions version implements the simulation grids with three-dimensional arrays.  The algorithm computes time steps of the currents in the aforementioned grids, setting up and solving spatial partial differential equations at each step \cite{Singh1992}.  I ran the simulation with the default parameters of a 258x258 grid ocean, a single processor, an error tolerance of $10^{-7}$, 20,000 meters between grid points, and 28,800 virtual seconds between timesteps.  Figure \ref{fig_ocean} shows that performance is nearly constant, increasing only slightly with the length of inserted delays, up through 100{\textmu}s.  Then with an inserted delay of 5ms, the performance takes a significant hit, running 2.36 times slower than without any inserted delay.
%\subsection{Hierarchical Radiosity}
%\begin{figure}
%\centering
%\includegraphics[width=\columnwidth]{ocean}
%\caption{The performance cost on the SPLASH-2 application RADIOSITY of placing targeted timing delays in the CentOS Linux kernel 2.4.21.}
%\label{fig_radiosity}
%\end{figure}
%The Hierarchical Radiosity Application \cite{Hanrahan1991} in SPLASH-2 quickly illuminates series of large polygonal patches, decomposing the scene into $O(n)$ blocks.  I ran this application with the room model (illumination as if the polygons are enclosed in a room), in batch mode, with a single process.  Figure \ref{fig_radiosity} shows that there is very little fluctuation in the performance of this application with respect to changes in targeted delay length.  Even with an inserted delay of 5ms, the application only sees a slowdown of less than one half of one percent.
%\subsection{Water Simulation}
%\begin{figure}
%\centering
%\includegraphics[width=\columnwidth]{water}
%\caption{The performance cost on the SPLASH-2 application WATER of placing targeted timing delays in the CentOS Linux kernel 2.4.21.}
%\label{fig_water}
%\end{figure}
%The Water Simulation in SPLASH-2 evaluates forces and potentials in a system of water molecules as an $n$-body problem \cite{Singh1992}.  The Spatial Data Structure algorithm approximates the solutions classically (not quantum mechanically), keeping track of the intermediary results in a 3-D spatial data structure in the cubical domain.  I used the default input parameters of $1.5 \times 10^{-16}$ seconds between timesteps, 512 molecules of water, 3 timesteps to simulate, and 1 processor.  Figure \ref{fig_water} shows a slight correlation between inserted delay in do\_mmap2 and the slowdown of the water simulation application.  With an inserted delay of 5ms, the Water Simulation experienced a 9.74\% slowdown.
%
%\section{Future Work}
%The next step is to show that randomized timing delays have a similar effect.  Our approach is to rewrite buggy multithreaded binaries, for which we have exploit scripts in hand, in the following way:
%\begin{enumerate}
%	\item Replace all function calls with jumps to variable-length NOP loops, different for each function.
%	\item At the end of these loops, jump to the originally intended function.
%	\item Randomize the NOP loop lengths on each rewrite.
%\end{enumerate}
%In this way, we can change the program timing by introducing randomness between experiments.  In a real-world scenario this would correspond to program rewrites at boot time, or some other periodic interval.  If the reduction in exploit success justifies the overhead of the timing delays, thread timing randomization could be an important defense against concurrency attacks.
%
%\section{Fennec Bug \#777045}
%Fennec, or Firefox for Mobile, contained a concurrency bug up until revision 24ed03720db7 on August 4th 2012.  This bug, when triggered, caused a doorhanger (similar to a popup) associated with one website to be displayed when viewing another website.  The bug was originally discovered by Mozilla developers running automated test suites on the Fennec code.  Specifically, the Robocop test driver, running in the talos test suite, with the test case "testCheck" - a checkerboard performance test - was shown by several developers to reproduce the bug.  It was quickly discovered that a race condition exists between the thread called to generate the doorhanger and the main thread used to display different web pages.  If the main thread "won" the race, the doorhanger could persist after its associated webpage was closed.  This appeared to be an ideal candidate for experimenting the hypothesis outlined above; however, I will now discuss the various setbacks that prevented me from even reproducing this bug, let alone randomly injecting NOPs into it.
%\subsection{Building with Clang}
%My first attempt at reproducing the bug involved trying to run testCheck in an Android emulator on my Mac.  Two things are necessary in order to run testCheck: 1) Fennec built for Android, and 2) an executable called ``xpcshell" built for the architecture that the test will run on (Darwin in this case).  However, a compatible versions of these two things were not buildable with Clang on Mac OS 10.9 at revision 3613cbdc3481 (shortly prior to the bug fix).  At first, compilation of Fennec was failing with the error message `JS\_GetNaNValue' has C-linkage specified, but returns user-defined type `jsval'.  This turned out to be because Robocop will not work with XUL Fennec - a more cross-platform-compatible version of Firefox.  However, even after building Fennec with API 14 and NDK r7c, the xpcshell binary from the Mozilla nightly builds was not compatible, failing with ``dyld: Library not loaded: @executable\_path/XUL".
%Attempts at building the same revision using Clang 3.0, targeting Darwin 9.2, with the Mac OS X 10.5 SDK, and targeting Mac OS X 10.5 also failed with the error message ``/Users/tag/Work/firefox/memory/mozjemalloc/jemalloc.c:6351:29: error: no member named `memalign' in `struct \_malloc\_zone\_t'"  Finally, after attempts to build xpcshell targeting Mac on Ubuntu 12.04 Desktop 64-but, and with some advice from some Mozilla developers, I decided to give up trying to compile with Clang, and switched to GCC.
%\subsection{Building with GCC}
%Right away, I was able to successfully build Fennec and Firefox from revision 3613cbdc3481 in an Ubuntu 12.04 VM.  However, testCheck was failing in talos with the error message talosError: ``Unable to copy `/tmp/tmpC9SIvv/profile' to remote device `/mnt/sdcard/tests/profile'".  In fact all of the talos tests were failing.  Tests were working better in the mochitest framework, but Fennec was crashing with API 14 (without GPU hardware rendering) in the Android emulator.  In fact the hardware GPU failed with APIs 14, 15, 16, and 19.
%\subsection{Real Device}
%At this point, I decided that it would be better to try on a real device, rather than continue to beat my head against the emulator, as it clearly had software graphics rendering issues.  I ordered a Samsung Galaxy Tab 2 with Android 4.1.1, rooted it with CF-AutoRoot, and installed ClockworkMod-restore.  Still mochitest-robotium failed on the device with API 14 and 16, with error message ``/sdcard/robotium.config: cannot open for write: Permission denied".  Downgrading to Android 4.0.4 (closer to the era of the bug gave more success.  In the end, I was able to get testCheck running on the device via the mochitest framework.  However, after 2,744 run, the bug was still not observed.

%{\footnotesize \bibliographystyle{acm}
%\bibliography{../common/bibliography}}
\bibliographystyle{IEEE}
\begin{thebibliography}{13}
\bibitem{Lu2008}
S. Lu, S. Park, E. Seo and Y. Zhou, "Learning from mistakes - A Comprehensive Study on Real World Concurrency Bug Characteristics," in \emph{Proceedings of the 13th international conference on Architectural support for programming languages and operating systems} - ASPLOS XIII, New York, NY, 2008.
\bibitem{Yang2011}
J. Yang, A. Cui, S. Stolfo and S. Sethumadhavan, "Concurrency Attacks," in HotPar'12 \emph{Proceedings of the 4th USENIX conference on Hot Topics in Parallelism}, Berkeley, CA, 2011.
\bibitem{Savage1997}
S. Savage, M. Burrows, G. Nelson, P. Sobalvarro and T. Anderson, "Eraser: a dynamic data race detector for multithreaded programs," \emph{ACM Transactions on Computer Systems}, vol. 15, no. 4, pp. 391-411, 1997.
\bibitem{Flanagan2004}
C. Flanagan and S. N. Freund, "Atomizer: a dynamic atomicity checker for multithreaded programs," in \emph{18th International Parallel and Distributed Processing Symposium}, 2004. Proceedings., 2004.
\bibitem{Laadan2011}
O. Laadan, C.-C. Tsai, N. Viennot, C. Blinn, P. S. Du, J. Yang and J. Nieh, "Finding Concurrency Errors in Sequential Codeâ€”OS-level, In-vivo Model Checking of Process Races," in \emph{Proceedings of the 13th USENIX conference on Hot topics in operating systems}, 2011.
\bibitem{Pratikakis2011}
P. Pratikakis, J. S. Foster and M. Hicks, "LOCKSMITH: Practical Static Race Detection for C," \emph{ACM Transactions on Programming Languages and Systems}, vol. 33, no. 1, pp. 1-55, 2011.
\bibitem{Kasikci2013}
B. Kasikci, C. Zamfir and G. Candea, "RaceMob: Crowdsourced Data Race Detection," in \emph{Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles} - SOSP '13, New York, NY, 2013.
\bibitem{Cui2011}
H. Cui, J. Wu, J. Gallagher, H. Guo and J. Yang, "Efficient Deterministic Multithreading through Schedule Relaxation," in \emph{Proceedings of the TwentyThird ACM Symposium on Operating Systems Principles} SOSP 11, 2011.
\bibitem{CVE2006-4814}
CVE-2006-4814. \url{http://www.cvedetails.com/cve/CVE-2006-4814/}
\bibitem{RHELbug180663}
Red Hat Bugzilla --- Bug 180663.\\\url{https://bugzilla.redhat.com/show_bug.cgi?id=180663}
\bibitem{Woo1995}
Woo, Steven Cameron, et al. "The SPLASH-2 programs: Characterization and methodological considerations." \emph{ACM SIGARCH Computer Architecture News}, Vol. 23. No. 2. ACM, 1995.
\bibitem{Singh1992}
Singh, Jaswinder Pal, Wolf-Dietrich Weber, and Anoop Gupta. "SPLASH: Stanford parallel applications for shared-memory." \emph{ACM SIGARCH Computer Architecture News} 20.1 (1992): 5-44.
\bibitem{Hanrahan1991}
Hanrahan, Pat, David Salzman, and Larry Aupperle. "A rapid hierarchical radiosity algorithm." \emph{ACM SIGGRAPH Computer Graphics}, Vol. 25. No. 4. ACM, 1991.
\end{thebibliography}

%\theendnotes

\end{document}